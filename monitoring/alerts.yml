groups:
  - name: artemis-alerts
    interval: 30s
    rules:
      - alert: HighMemoryWriteLatency
        expr: histogram_quantile(0.95, rate(memory_bus_write_latency_seconds_bucket[5m])) > 0.2
        for: 5m
        labels:
          severity: warning
          component: memory_bus
        annotations:
          summary: "High memory write latency detected"
          description: "Memory bus write latency p95 is {{ $value | humanizeDuration }} (threshold: 200ms) on instance {{ $labels.instance }}"

      - alert: MemoryBusWriteLatencyCritical
        expr: histogram_quantile(0.95, rate(memory_bus_write_latency_seconds_bucket[5m])) > 0.5
        for: 2m
        labels:
          severity: critical
          component: memory_bus
        annotations:
          summary: "Critical memory write latency"
          description: "Memory bus write latency p95 is {{ $value | humanizeDuration }} (threshold: 500ms) on instance {{ $labels.instance }}"

      - alert: HighSyncLag
        expr: governance_sync_lag_milliseconds > 300
        for: 3m
        labels:
          severity: warning
          component: governance
        annotations:
          summary: "High synchronization lag detected"
          description: "Governance sync lag is {{ $value | humanizeDuration }} (threshold: 300ms) on instance {{ $labels.instance }}"

      - alert: SyncLagCritical
        expr: governance_sync_lag_milliseconds > 1000
        for: 1m
        labels:
          severity: critical
          component: governance
        annotations:
          summary: "Critical synchronization lag"
          description: "Governance sync lag is {{ $value | humanizeDuration }} (threshold: 1000ms) on instance {{ $labels.instance }}"

      - alert: AgentQuarantine
        expr: governance_agents_quarantined > 0
        for: 2m
        labels:
          severity: warning
          component: governance
        annotations:
          summary: "Agents in quarantine"
          description: "{{ $value }} agent(s) are in quarantine on instance {{ $labels.instance }}"

      - alert: MultipleAgentsQuarantined
        expr: governance_agents_quarantined > 5
        for: 1m
        labels:
          severity: critical
          component: governance
        annotations:
          summary: "Multiple agents quarantined"
          description: "{{ $value }} agents are in quarantine (threshold: 5) on instance {{ $labels.instance }}"

      - alert: HighSandboxViolationRate
        expr: rate(hebbian_sandbox_violations_total[5m]) > 0.1
        for: 5m
        labels:
          severity: warning
          component: hebbian
        annotations:
          summary: "High sandbox violation rate"
          description: "Sandbox violation rate is {{ $value | humanize }} violations/sec (threshold: 0.1/sec) on instance {{ $labels.instance }}"

      - alert: SandboxViolationRateCritical
        expr: rate(hebbian_sandbox_violations_total[5m]) > 0.5
        for: 2m
        labels:
          severity: critical
          component: hebbian
        annotations:
          summary: "Critical sandbox violation rate"
          description: "Sandbox violation rate is {{ $value | humanize }} violations/sec (threshold: 0.5/sec) on instance {{ $labels.instance }}"

      - alert: PrometheusDown
        expr: up{job="prometheus"} == 0
        for: 1m
        labels:
          severity: critical
          component: monitoring
        annotations:
          summary: "Prometheus is down"
          description: "Prometheus monitoring service is unavailable"

      - alert: HighErrorRate
        expr: rate(artemis_requests_total{status=~"5.."}[5m]) > 0.05
        for: 5m
        labels:
          severity: warning
          component: app
        annotations:
          summary: "High error rate detected"
          description: "Error rate is {{ $value | humanizePercentage }} on instance {{ $labels.instance }}"
